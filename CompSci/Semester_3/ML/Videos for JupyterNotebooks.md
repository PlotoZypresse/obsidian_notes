Check mark if watched and written notes are done

- **Basic Concepts in Machine Learning**:
  - [x] A Gentle Introduction to Machine Learning
  - [x] Machine Learning Fundamentals: Bias and Variance [[Bias and Variance]]

- **Linear Predictors and Regression Analysis**:
  - [x] Linear Regression, Clearly Explained!!! [[Linear Regression]]
  - [x] Regularization Part 1: L2, Ridge Regression [[L2 Ridge Regression]]
  - [x] Regularization Part 2: L1, Lasso Regression [[L1 Lasso Regression]]
  - [x] Regularization Part 2.5: Ridge vs Lasso Visualized (or why Lasso can set parameters to 0 and Ridge can’t)
  - [x] Regularization Part 3: Elastic-Net Regression [[Elastic-Net Regression]]
  - [ ] Linear Discriminant Analysis (LDA) clearly explained [[LDA]] 
  - [ ] Gradient Descent [[Gradien Descent]]
  - [ ] Stochastic Gradient Descent

- **Classification and Logistic Regression**:
  - [x] Machine Learning Fundamentals: The Confusion Matrix [[Confusion Matrix]]
  - [x] Machine Learning Fundamentals: Sensitivity and Specificity [[Sensitivity and Specificity]]
  - [x] ROC and AUC [[ROC and AUC]] 
  - [x] Logistic Regression [[Logistic Regression]] 
  - [ ] Logistic Regression, Details Part 1: Coefficients [[Logistic Regression Coefficients]]
  - [x] Logistic Regression, Details Part 2: Maximum Likelihood [[Logistic Regression Maksimum Likelihood Estimation]]
  - [ ] Logistic Regression, Details Part 3: R-squared and its p-value [[Logistic Regression R squared and p-value]] 

- **Probability Theory and Bayesian Learning**:
  - [ ] Entropy, Clearly Explained!!! [[Entropy]]
  - [ ] Mutual Information, Clearly Explained!!! [[Mutual Information]]

- **Unsupervised Learning and Clustering**:
  - [x] Machine Learning Fundamentals: Cross Validation [[Cross Validation]]
  - [ ] K-Means Clustering [[K-Means]]
  - [ ] Clustering with DBSCAN
  - [ ] Hierarchical Clustering
  - [ ] K-nearest Neighbor 

- **Deep Learning and Neural Networks**:
  - [ ] Neural Networks Part 0: Neural Networks are not Scary!!!
  - [ ] Neural Networks Part 1: Inside the black box
  - [ ] Neural Networks Part 2: Backpropagation Main Ideas
  - [ ] Neural Networks Part 8: Image Classification with Convolutional Neural Networks (CNNs)
  - [ ] Neural Networks Part 9: Recurrent Neural Networks (RNNs)
  - [ ] Neural Networks Part 10: Long Short-Term Memory (LSTM)

- **Dimensionality Reduction and PCA**:
  - [ ] Principal Component Analysis (PCA) Step-by-Step [[PCA]]
  - [x] Principal Component Analysis (PCA) explained in less than 5 minutes
  - [x] PCA – Practical Tips
  - [x] PCA in Python

- **Decision Trees and Ensemble Methods**:
  - [ ] Decision and Classification Trees, Clearly Explained!!!
  - [ ] Decision Trees Part 2: Feature Selection and Missing Data
  - [ ] Regression Trees
  - [ ] Random Forests Part 1: Building, using and evaluating
  - [ ] Gradient Boost Part 1: Regression Main Ideas
  - [ ] XGBoost Part 1: Regression
  - [ ] XGBoost Part 2: Classification

- **Support Vector Machines**:
  - [ ] Support Vector Machines (SVM)
  - [ ] Part 2: The Polynomial Kernel
  - [ ] Part 3: The Radial (RBF) Kernel
