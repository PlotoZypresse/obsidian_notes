## Overview

Decision trees are a type of supervised learning algorithm that can be used for both classification and regression tasks. They are popular due to their simplicity, interpretability, and applicability to various types of data.

## Key Concepts

- **Node**: A point where the data is split.
- **Root Node**: The topmost decision node.
- **Leaf Node**: A node that doesn't split further, representing a decision or outcome.
- **Branch**: A subsection of the entire tree.

## How Decision Trees Work

1. **Splitting**: The process of dividing a node into two or more sub-nodes.
2. **Decision Node**: When a sub-node splits into further sub-nodes.
3. **Pruning**: Removing a section of the tree to avoid overfitting.

## Types of Decision Trees

- **Categorical Variable Decision Tree**: Used for categorical target variables.
- **Continuous Variable Decision Tree**: Used for continuous target variables.

## Advantages

- Easy to understand and interpret.
- Requires little data preparation.
- Can handle both numerical and categorical data.

## Disadvantages

- Prone to overfitting.
- Can become unstable with small variations in data.
- Biased with imbalanced datasets.

## Applications

- Medical diagnosis.
- Credit risk analysis.
- Classification tasks in various industries.
---
#reviewML