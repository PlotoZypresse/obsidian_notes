## Lesson 1: Basic Concepts
  - [x] Machine learning in the real world
  - [x] Definition of machine learning
  - [x] Supervised/unsupervised learning https://www.youtube.com/watch?v=W01tIRP_Rqs
  - [x] Training/testing https://www.youtube.com/watch?v=P2NqrFp8usY
  - [x] Performance evaluation https://www.youtube.com/watch?v=LbX4X71-TFI
  - [x] Empirical risk minimization https://www.youtube.com/watch?v=8fsJCyBOizQ
  - [x] Overfitting/underfitting https://www.youtube.com/watch?v=EuBBz3bI-aA https://www.youtube.com/watch?v=T9NtOa-IITo
  - [ ] Additional Reading:
    - [ ] Bishop, Section 1.1
    - [x] Shalev-Schwartz, Chapter 2

## Lesson 2: Linear Predictors
  - [x] Least-squares regression https://www.youtube.com/watch?v=7ArmBVF2dCs
  - [x] Distance metrics and norms https://www.youtube.com/watch?v=FiSy6zWDfiA
  - [x] Ridge regression https://www.youtube.com/watch?v=Q81RR3yKn30
  - [x] Gradient descent https://www.youtube.com/watch?v=IHZwWFHWa-w
  - [x] Lasso regression https://www.youtube.com/watch?v=NGf0voTMlcs
  - [ ] Additional reading:
    - [ ] Bishop, Section 3.1
    - [ ] Hastie, Sections 3.1, 3.2, 3.4
 
## Lesson 3-4: Classification
  - [x] Logistic regression https://www.youtube.com/watch?v=yIYKR4sgzI8
  - [x] k-nearest neighbor classifier https://www.youtube.com/watch?v=4HKqjENq9OU
  - [x] Precision/recall https://www.youtube.com/watch?v=qWfzIYCvBqo&pp=ygUhcHJlY2lzaW9uL3JlY2FsbCBtYWNoaW5lIGxlYXJuaW5n https://www.youtube.com/watch?v=vP06aMoz4v8&t=141s&pp=ygUhcHJlY2lzaW9uL3JlY2FsbCBtYWNoaW5lIGxlYXJuaW5n https://www.youtube.com/watch?v=Kdsp6soqA7o&t=331s&pp=ygUhcHJlY2lzaW9uL3JlY2FsbCBtYWNoaW5lIGxlYXJuaW5n
  - [x] Receiver Operating Characteristics ROC https://www.youtube.com/watch?v=4jRBRDbJemM&t=842s&pp=ygUiUmVjZWl2ZXIgT3BlcmF0aW5nIENoYXJhY3RlcmlzdGljcw%3D%3D
  - [ ] Validation and hyperparameter tuning https://www.youtube.com/watch?v=PK37PqkIOg4&list=PLfFghEzKVmjunyr8OPegxrX7y83IDuZNV
  - [x] k-Fold Cross Validation  https://www.youtube.com/watch?v=fSytzGwwBVw&pp=ygUkVmFsaWRhdGlvbiBhbmQgaHlwZXJwYXJhbWV0ZXIgdHVuaW5n
  - [ ] Additional Reading:
    - [ ] Bishop, Sections 4.1.1, 4.1.2, 4.1.3, 4.3.2, 4.3.4 and page 197

## Lesson 5-6-7: Probability theory
https://www.youtube.com/watch?v=wgV0rjJqpqI&list=PLBh2i93oe2qswFOC98oSFc37-0f4S3D4z
  - [x] Axioms, events, sigma-algebras https://www.youtube.com/watch?v=xZ69KEg7ccU&pp=ygUeQXhpb21zLCBldmVudHMsIHNpZ21hLWFsZ2VicmFz
  - [x] Conditional probability, Bayes theorem, and independence 
  - [ ] Random variables, expectation, variance
  - [ ] Probability density functions, cumulative distribution functions
  - [ ] Distributions: Normal, Bernoulli, Dirichlet
  - [ ] Estimators and bias
  - [ ] Concentration inequalities (Markov, Chebyshev, Hoeffding) https://www.youtube.com/watch?v=cqe7QByuPRE&pp=ygUaQ29uY2VudHJhdGlvbiBpbmVxdWFsaXRpZXM%3D
  - [ ] Additional Reading:
    - [ ] Bishop, Section 1.2
    - [ ] Mohri, Appendix C1-C5

## Lesson 8-9: Statistical learning theory
  - [ ] Probably Approximately Correct (PAC) learning https://www.youtube.com/watch?v=X4Oxst5huQA
  - [ ] Vapnik Chervonenkis dimension Vapnik Chervonenkis dimension
  - [ ] The bias-variance dilemma https://www.youtube.com/watch?v=EuBBz3bI-aA&pp=ygUZVGhlIGJpYXMtdmFyaWFuY2UgZGlsZW1tYQ%3D%3D https://www.youtube.com/watch?v=W5uUYnSHDhM&pp=ygUZVGhlIGJpYXMtdmFyaWFuY2UgZGlsZW1tYQ%3D%3D
  - [ ] Additional Reading:
    - [ ] Mohri, Chapters 2 and 3

## Lesson 9-10: Bayesian learning
  - [ ] Maximum likelihood estimation https://www.youtube.com/watch?v=XepXtl9YKwc&pp=ygUdTWF4aW11bSBsaWtlbGlob29kIGVzdGltYXRpb24%3D
  - [ ] Bayesian linear regression and curve fitting https://www.youtube.com/watch?v=Z6HGJMUakmc&pp=ygUtQmF5ZXNpYW4gbGluZWFyIHJlZ3Jlc3Npb24gYW5kIGN1cnZlIGZpdHRpbmcg
  - [ ] Maximum A-Posteriori Estimation https://www.youtube.com/watch?v=845xlSrrB38&pp=ygUfTWF4aW11bSBBLVBvc3RlcmlvcmkgRXN0aW1hdGlvbg%3D%3D
  - [ ] Naive Bayes Classifier https://www.youtube.com/watch?v=O2L2Uv9pdDA&pp=ygUWTmFpdmUgQmF5ZXMgQ2xhc3NpZmllcg%3D%3D https://www.youtube.com/watch?v=lFJbZ6LVxN8&pp=ygUWTmFpdmUgQmF5ZXMgQ2xhc3NpZmllcg%3D%3D
  - [ ] Additional Reading:
    - [ ] Bishop, Chapter 3, Sections 4.1, 4.2, 4.3

## Lesson 11: Unsupervised learning
  - [ ] Dimensionality Reduction: PCA https://www.youtube.com/watch?v=HMOI_lkzW08&pp=ygUdRGltZW5zaW9uYWxpdHkgUmVkdWN0aW9uOiBQQ0E%3D
  - [ ] Clustering: k-Means https://www.youtube.com/watch?v=4b5d3muPQmA&pp=ygUTQ2x1c3RlcmluZzogay1NZWFucw%3D%3D
  - [ ] Density Estimation: Mixture of Gaussians with EM https://www.youtube.com/watch?v=qMTuMa86NzU&pp=ygUwRGVuc2l0eSBFc3RpbWF0aW9uOiBNaXh0dXJlIG9mIEdhdXNzaWFucyB3aXRoIEVN
  - [ ] Additional Reading:
    - [ ] Bishop, Sections 9.1, 9.2, and 12.1

## Lesson 12-13: Deep learning
https://www.youtube.com/watch?v=7YaqzpitBXw&pp=ygUYZGVlcCBsZWFybmluZyBwZXJjZXB0cm9u
https://www.youtube.com/watch?v=aircAruvnKk&pp=ygUNZGVlcCBsZWFybmluZw%3D%3D
  - [ ] Perceptrons https://www.youtube.com/watch?v=4Gac5I64LM4&pp=ygUYZGVlcCBsZWFybmluZyBwZXJjZXB0cm9u
  - [ ] Activation functions
  - [ ] Multi-layer perceptrons https://www.youtube.com/watch?v=7YaqzpitBXw&pp=ygUYZGVlcCBsZWFybmluZyBwZXJjZXB0cm9u
  - [ ] Backpropagation
  - [ ] Stochastic Gradient Descent https://www.youtube.com/watch?v=vMh0zPT0tLI&pp=ygUcIFN0b2NoYXN0aWMgR3JhZGllbnQgRGVzY2VudA%3D%3D
  - [ ] Case Study: Handwritten Digit Recognition
  - [ ] Additional Reading:
    - [ ] Bishop, Section 5.3
    - [ ] Goodfellow, Chapter 6 (see the "Backpropagation" link on the right panel)

## Lesson 13-14: Learning and controlling dynamical systems
  - [ ] Recurrent neural networks https://www.youtube.com/watch?v=AsNTP8Kwu80&pp=ygUZUmVjdXJyZW50IG5ldXJhbCBuZXR3b3Jrcw%3D%3D
  - [ ] Backpropagation through time https://www.youtube.com/watch?v=0XdPIqi0qpg&pp=ygUcQmFja3Byb3BhZ2F0aW9uIHRocm91Z2ggdGltZQ%3D%3D
  - [ ] Reinforcement learning basic concepts https://www.youtube.com/watch?v=nIgIv4IfJ6s&pp=ygUXUmVpbmZvcmNlbWVudCBsZWFybmluZyA%3D
  - [ ] Q-learning https://www.youtube.com/watch?v=kEGAMppyWkQ&pp=ygUXUmVpbmZvcmNlbWVudCBsZWFybmluZyA%3D
  - [ ] Bellman equation https://www.youtube.com/watch?v=14BfO5lMiuk&pp=ygUQQmVsbG1hbiBlcXVhdGlvbg%3D%3D
  - [ ] Additional Reading:
    - [ ] Mohri, Chapter 17

## Lesson 15: Kernel methods
  - [ ] Feature space transformations https://www.youtube.com/watch?v=B6mPphwAXZk&pp=ygUdRmVhdHVyZSBzcGFjZSB0cmFuc2Zvcm1hdGlvbnM%3D
  - [ ] Kernel trick https://www.youtube.com/watch?v=Q7vT0--5VII&pp=ygUMS2VybmVsIHRyaWNr
  - [ ] Mercer's theorem https://www.youtube.com/watch?v=Zi3Fu0M3QFI&pp=ygURIE1lcmNlcidzIHRoZW9yZW0%3D
  - [ ] Kernel regression https://www.youtube.com/watch?v=ZhJTGBbR18o&pp=ygURS2VybmVsIHJlZ3Jlc3Npb24%3D
  - [ ] Support vector machines https://www.youtube.com/watch?v=efR1C6CvhmE&pp=ygUXU3VwcG9ydCB2ZWN0b3IgbWFjaGluZXM%3D
  - [ ] Additional Reading:
    - [ ] Bishop, Sections 6.1, 6.2, 7.1

## Lesson 16: Ensemble learning
  - [ ] Bootstrap Aggregation (Bagging) https://www.youtube.com/watch?v=Xz0x-8-cgaQ&pp=ygUfQm9vdHN0cmFwIEFnZ3JlZ2F0aW9uIChCYWdnaW5nKQ%3D%3D
  - [ ] Boosting (AdaBoost, Gradient Boosting) https://www.youtube.com/watch?v=LsK-xG1cLYA&t=330s&pp=ygUmQm9vc3RpbmcgKEFkYUJvb3N0LCBHcmFkaWVudCBCb29zdGluZyk%3D https://www.youtube.com/watch?v=3CC4N4z3GJc&pp=ygUmQm9vc3RpbmcgKEFkYUJvb3N0LCBHcmFkaWVudCBCb29zdGluZyk%3D
  - [ ] Federated learning https://www.youtube.com/watch?v=zqv1eELa7fs&pp=ygUSRmVkZXJhdGVkIGxlYXJuaW5n
  - [ ] Additional Reading:
    - [ ] Decision Trees: Bishop, Section 14.4
    - [ ] Boosting: Hastie, Chapter 10
    - [ ] Bishop, Section 14.3

